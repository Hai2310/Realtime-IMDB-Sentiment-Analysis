{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21db1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "import time\n",
    "import traceback\n",
    "from functools import partial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc75ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkConfig :\n",
    "    def create_sparksession() :\n",
    "        spark = SparkSession.builder.appName(\"IMDB movie\") \\\n",
    "                                    .config(\"spark.driver.memory\" , \"8g\") \\\n",
    "                                    .config(\"spark.executors.memory\" , \"4g\") \\\n",
    "                                    .config('spark.streaming.stopGracefullyOnShutdown' , True) \\\n",
    "                                    .config(\"spark.sql.shuffle.partitions\" , \"20\") \\\n",
    "                                    .config(\"spark.jars.packages\" , \"org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1,\" \\\n",
    "                                                                    \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.4.0\") \\\n",
    "                                    .config(\"spark.jars\" , \"/home/enovo/prj/test/postgresql-42.7.3.jar\") \\\n",
    "                                    .getOrCreate()\n",
    "        return spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8607e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDB_Schema :\n",
    "    def movie_schema() :\n",
    "        movie_schema = ArrayType(StructType([\n",
    "            StructField('movie_id' , StringType() , True) , \n",
    "            StructField(\"title\" , StringType() , True) ,\n",
    "            StructField(\"rating\" , FloatType() , True) , \n",
    "            StructField(\"year\" , IntegerType() , True) ,\n",
    "            StructField(\"vote_count\" , StringType() , True) ,\n",
    "            StructField(\"runtime\" , StringType() , True) ,\n",
    "            StructField(\"items\" , StringType() , True ) ,\n",
    "            StructField(\"country\" , StringType() , True) ,\n",
    "            StructField(\"language\" , StringType() , True) ,\n",
    "            StructField(\"company\" , StringType() , True) ,\n",
    "            StructField(\"budget\" , StringType() , True) , \n",
    "            StructField(\"revenue\" , StringType() , True) ,\n",
    "            StructField(\"plot\" , StringType() , True) ,\n",
    "            StructField(\"poster\" , StringType() , True) ,\n",
    "            StructField(\"url\" , StringType() , True)\n",
    "        ]))\n",
    "        return movie_schema\n",
    "    \n",
    "    def actor_schema()  :\n",
    "        actor_schema = ArrayType(StructType([\n",
    "            StructField(\"actor_id\" , StringType() , True) ,\n",
    "            StructField(\"director\" , StringType() , True) ,\n",
    "            StructField(\"writers\" , StringType() , True) ,\n",
    "            StructField(\"stars\" , StringType() , True) ,\n",
    "            StructField(\"movie_id\" , StringType() , True)\n",
    "        ]))\n",
    "        return actor_schema \n",
    "    \n",
    "    def review_schema() : \n",
    "        review_schema = ArrayType(StructType([\n",
    "            StructField(\"review_id\" , StringType() , True) , \n",
    "            StructField(\"title_review\" , StringType() , True) ,\n",
    "            StructField(\"comment\" , StringType() , True) ,\n",
    "            StructField(\"star\" , StringType() , True) ,\n",
    "            StructField(\"like\" , StringType() , True) ,\n",
    "            StructField(\"dislike\" , StringType() , True) ,\n",
    "            StructField(\"date\" , StringType() , True) ,\n",
    "            StructField(\"user_name\" , StringType() , True) , \n",
    "            StructField(\"movie_id\" , StringType() , True)\n",
    "        ]))\n",
    "        return review_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4fe97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader :\n",
    "    def __init__(selt) :\n",
    "        selt.spark = SparkConfig.create_sparksession()\n",
    "        \n",
    "    def movie_load(selt) :\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== Starting load movie ===\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        movie = selt.spark.readStream.format(\"kafka\" ).option(\"kafka.bootstrap.servers\" , \"localhost:9092\" ) \\\n",
    "                                                .option(\"subscribe\" , \"movie\") \\\n",
    "                                                .option(\"startingOffsets\" , \"earliest\") \\\n",
    "                                                .load()\n",
    "        \n",
    "        movie_generate = movie.withColumn(\"movie_ts\" , col(\"timestamp\")) \\\n",
    "                                        .withWatermark(\"movie_ts\" , \"10 minutes\")\n",
    "        \n",
    "        movie_generate = movie_generate.withColumn(\"value\" , explode(\n",
    "                                                    from_json(col(\"value\").cast(\"string\") , IMDB_Schema.movie_schema()))) \\\n",
    "                                                    .select(\"value.*\" , \"movie_ts\")\n",
    "        \n",
    "        \n",
    "        print(\"=== Loaded movie successfully ===\")\n",
    "        return movie_generate\n",
    "    \n",
    "    def actor_load(selt) :\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== Starting load actor ===\")\n",
    "        print(\"=\"*60)\n",
    "        actor = selt.spark.readStream.format(\"kafka\" ).option(\"kafka.bootstrap.servers\" , \"localhost:9092\" ) \\\n",
    "                                                .option(\"subscribe\" , \"actor\") \\\n",
    "                                                .option(\"startingOffsets\" , \"earliest\") \\\n",
    "                                                .load()\n",
    "        \n",
    "        actor_generate = actor.withColumn(\"actor_ts\" , col(\"timestamp\")) \\\n",
    "                                        .withWatermark(\"actor_ts\" , \"10 minutes\")\n",
    "        \n",
    "        actor_generate = actor_generate.withColumn(\"value\" , explode(\n",
    "                                                    from_json(col(\"value\").cast(\"string\") , IMDB_Schema.actor_schema()))) \\\n",
    "                                                    .select(\"value.*\" , \"actor_ts\")\n",
    "        \n",
    "        \n",
    "        print(\"=== Loaded actor successfully ===\")\n",
    "        return actor_generate    \n",
    "    \n",
    "    def review_load(selt) :\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== Starting review actor ===\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        review = selt.spark.readStream.format(\"kafka\" ).option(\"kafka.bootstrap.servers\" , \"localhost:9092\" ) \\\n",
    "                                                .option(\"subscribe\" , \"review\") \\\n",
    "                                                .option(\"startingOffsets\" , \"earliest\") \\\n",
    "                                                .load()\n",
    "        \n",
    "        review_generate = review.withColumn(\"review_ts\" , col(\"timestamp\")) \\\n",
    "                                        .withWatermark(\"review_ts\" , \"10 minutes\")\n",
    "        \n",
    "        review_generate = review_generate.withColumn(\"value\" , explode(\n",
    "                                                    from_json(col(\"value\").cast(\"string\") , IMDB_Schema.review_schema()))) \\\n",
    "                                                    .select(\"value.*\" , \"review_ts\")\n",
    "        \n",
    "        \n",
    "        print(\"=== Loaded review successfully ===\")\n",
    "        return review_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6b1e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_77068/1895771571.py:11: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  movie_revenue_clean = movie.withColumn(\"revenue\" , regexp_replace(col(\"revenue\") , \"[\\$,]\" , \"\")) \\\n",
      "/tmp/ipykernel_77068/1895771571.py:19: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  .withColumn(\"budget\" , regexp_replace(col(\"budget\") , \"[\\$,]\" , \"\")) \\\n",
      "/tmp/ipykernel_77068/1895771571.py:40: SyntaxWarning: invalid escape sequence '\\['\n",
      "  actor_clean = actor.withColumn(\"writers\" , regexp_replace(col(\"writers\") , '[\\[\\]\"]' , \"\") ) \\\n",
      "/tmp/ipykernel_77068/1895771571.py:41: SyntaxWarning: invalid escape sequence '\\['\n",
      "  .withColumn(\"stars\" , regexp_replace(col(\"stars\") , '[\\[\\]\"]' , \"\") )\n"
     ]
    }
   ],
   "source": [
    "class DataClean :\n",
    "    def movie_clean(movie) :\n",
    "        # Lọc các record rác\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== Starting clean movie ===\")\n",
    "        print(\"=\"*60)  \n",
    "\n",
    "        movie = movie.filter(~col(\"movie_id\").startswith(\"{\"))\n",
    "\n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột revenue\n",
    "        movie_revenue_clean = movie.withColumn(\"revenue\" , regexp_replace(col(\"revenue\") , \"[\\$,]\" , \"\")) \\\n",
    "                                    .withColumn(\"revenue\" , trim(col(\"revenue\")) ) \\\n",
    "                                    .withColumn(\"revenue\" , when(col(\"revenue\") == \"\" , 0).otherwise(col(\"revenue\"))) \\\n",
    "                                    .withColumn(\"revenue\" , col(\"revenue\").cast('int')) \n",
    "        \n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột budget\n",
    "        movie_budget_clean = movie_revenue_clean.withColumn(\"budget\" , when(col(\"budget\") == \"\" , \"0\").otherwise(col(\"budget\"))) \\\n",
    "                                                    .withColumn(\"budget\" , split(col(\"budget\") , \" \").getItem(0)) \\\n",
    "                                                    .withColumn(\"budget\" , regexp_replace(col(\"budget\") , \"[\\$,]\" , \"\")) \\\n",
    "                                                    .withColumn(\"budget\" , trim(col(\"budget\")) ) \\\n",
    "                                                    .withColumn(\"budget\" , col(\"budget\").cast('int'))\n",
    "        \n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột vote_count\n",
    "        movie_clean =  movie_budget_clean.withColumn(\"vote_count\" ,\n",
    "                            when(col(\"vote_count\").endswith(\"M\"),  regexp_replace(col(\"vote_count\") , \"M\" , \"\").cast(\"double\") * 1_000_000 ) \\\n",
    "                            .when(col(\"vote_count\").endswith(\"K\"), regexp_replace(col(\"vote_count\") , \"K\" , \"\").cast(\"double\") * 1_000  ) \\\n",
    "                            .otherwise(0) \\\n",
    "                            .cast(\"int\"))\n",
    "        print(\"=== Cleaned movie successfully ===\")\n",
    "        return movie_clean\n",
    "    \n",
    "    def actor_clean(actor) :\n",
    "        # Lọc các record rác\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== Starting clean actor ===\")\n",
    "        print(\"=\"*60)  \n",
    "        actor = actor.filter(~col(\"actor_id\").startswith(\"{\"))\n",
    "\n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột writers và stars\n",
    "        actor_clean = actor.withColumn(\"writers\" , regexp_replace(col(\"writers\") , '[\\[\\]\"]' , \"\") ) \\\n",
    "                        .withColumn(\"stars\" , regexp_replace(col(\"stars\") , '[\\[\\]\"]' , \"\") )\n",
    "        print(\"=== Cleaned actor successfully ===\")\n",
    "        return actor_clean\n",
    "    \n",
    "    def review_clean(review) : \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== Starting clean review ===\")\n",
    "        print(\"=\"*60)  \n",
    "\n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột star\n",
    "        review_star_clean = review.withColumn(\"star\" , when(col(\"star\") == \"\" , \"0\") \\\n",
    "                                                .otherwise(col(\"star\")) \\\n",
    "                                                .cast(\"int\") )\n",
    "        \n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột like\n",
    "        review_like_clean = review_star_clean.withColumn(\"like\" , \n",
    "                                            when(col(\"like\").endswith(\"K\") ,\n",
    "                                                trim(regexp_replace(col(\"like\") , \"K\" , \"\")).cast(\"double\") * 1_000 ) \\\n",
    "                                            .when(col(\"like\") == \"\" , \"0\") \\\n",
    "                                            .otherwise(trim(col(\"like\"))) \\\n",
    "                                            .cast(\"int\"))\n",
    "        \n",
    "        # Chuyển đổi kiểu dữ liệu , làm sạch cột dislike\n",
    "        review_dislike_clean = review_like_clean.withColumn(\"dislike\" , \n",
    "                                            when(col(\"dislike\").endswith(\"K\") , \n",
    "                                                trim(regexp_replace(col(\"dislike\") , \"K\" , \"\")).cast(\"double\") * 1_000 ) \\\n",
    "                                            .when(col(\"dislike\") == \"\" , \"0\") \\\n",
    "                                            .otherwise(trim(col(\"dislike\"))) \\\n",
    "                                            .cast(\"int\"))\n",
    "        \n",
    "        # Xóa cột không cần thiết\n",
    "        review_clean = review_dislike_clean.drop(\"date\")\n",
    "        print(\"=== Cleaned review successfully ===\")\n",
    "\n",
    "        return review_clean\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6df4621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 334:>                                                      (0 + 12) / 20]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:12 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 13315 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  18  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:19 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 6156 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  19  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 6039 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  20  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:31 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 6071 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  21  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n"
     ]
    }
   ],
   "source": [
    "class AnalysisSentiment :    \n",
    "    # ===================================================================\n",
    "    # 1 : Top đánh giá ,doanh thu ,lợi nhuận của các phim trong từng nước \n",
    "    # ===================================================================\n",
    "\n",
    "    def top_country(movie) :\n",
    "        # Thêm cột lợi nhuận\n",
    "        print(\"Analysis 1 : Top ratings, revenue, and profits of films in each country\")\n",
    "        movie_profit = movie.withColumn(\"profit\" , when(col(\"revenue\") > 0 , col(\"revenue\") - col(\"budget\")) \\\n",
    "                                            .otherwise(0))\n",
    "        # Lấy ra top theo country và language\n",
    "        top_country = movie_profit.groupBy(\"country\" , \"language\",\"movie_ts\").agg(avg(\"rating\").alias(\"avg_rating\") ,\n",
    "                                                                        sum(\"revenue\").alias(\"total_revenue\") ,\n",
    "                                                                        count(\"movie_id\").alias(\"total_movie\") ,\n",
    "                                                                        sum(\"budget\").alias(\"total_budget\") ,\n",
    "                                                                        avg(\"profit\").alias(\"avg_profit\"))\n",
    "        return top_country\n",
    "\n",
    "    # ===================================================================\n",
    "    # 2 : Phân tích cảm xúc người dùng\n",
    "    # ===================================================================\n",
    "    def top_user_sentiment(review , movie) :\n",
    "        print(\"Analysis 2 : Analytics user Sentiment\")\n",
    "\n",
    "        user_sentiment = review.join(broadcast(movie) , \"movie_id\" , \"inner\") \n",
    "\n",
    "        top_user_sentiment = user_sentiment.groupBy(\"title\" , \"rating\" , \"review_ts\").agg(count(\"review_id\").alias(\"total_review\") ,\n",
    "                                                                        sum(\"like\").alias(\"total_like\") ,\n",
    "                                                                        sum(\"dislike\").alias(\"total_dislike\") ,\n",
    "                                                                    when(sum(\"like\")+sum(\"dislike\") > 0 ,\n",
    "                                                                     (sum(\"like\")/(sum(\"like\")+sum(\"dislike\")))).otherwise(0.0).alias(\"like_ratio\")\n",
    "                                                                        )\n",
    "\n",
    "        return top_user_sentiment\n",
    "    # ===================================================================\n",
    "    # 3 : Top các đạo diễn có lượng rating , revenue cao nhất\n",
    "    # ===================================================================\n",
    "\n",
    "    def top_director_rate(actor , movie) :\n",
    "        print(\"Analysis 3 : Top directors with the highest ratings and revenue.\")\n",
    "\n",
    "        director_rate = actor.join(broadcast(movie) , \"movie_id\" , \"inner\") \n",
    "\n",
    "        top_director_rate = director_rate.groupBy(\"director\" , \"actor_ts\").agg(avg(\"rating\").alias(\"avg_rating\") ,\n",
    "                                                        count(\"movie_id\").alias(\"total_movies\") ,\n",
    "                                                        sum(\"revenue\").alias(\"total_revenue\"))\n",
    "        \n",
    "        return top_director_rate\n",
    "\n",
    "    # ===================================================================\n",
    "    # 4 : Xu hướng đánh giá theo năm \n",
    "    # ===================================================================\n",
    "    def rating_per_year(review , movie) :\n",
    "        print(\"Analysis 4 : Annual evaluation trends\")\n",
    "\n",
    "        review_join = review.join(broadcast(movie) , \"movie_id\" , \"inner\")\n",
    "\n",
    "        review_dt = review_join.dropDuplicates([\"review_id\" , \"movie_id\"])\n",
    "\n",
    "        rating_per_year = review_dt.groupBy(\"year\" , \"review_ts\").agg(avg(\"rating\").alias(\"avg_rating\") ,\n",
    "                                                        count(\"movie_id\").alias(\"total_movie\") ,\n",
    "                                                        count(\"review_id\").alias(\"total_review\"))\n",
    "        \n",
    "        return rating_per_year\n",
    "\n",
    "    # ===================================================================\n",
    "    # 5 : Khai phá dữ liệu , dự đoán cảm xúc người dùng\n",
    "    # ===================================================================\n",
    "    def data_mining(review) :    \n",
    "        \n",
    "        review_label =  review.withColumn(\"sentiment\" , when(col(\"star\") >= 8 , \"Positive\") \\\n",
    "                                                            .when(col(\"star\") >= 5 , \"Neutral\") \\\n",
    "                                                            .otherwise(\"Negative\")) \n",
    "        pdf = review_label.toPandas()\n",
    "\n",
    "\n",
    "        # ----------------------------\n",
    "        # 1. Star distribution\n",
    "        # ----------------------------\n",
    "        plt.figure(figsize=(6,4))\n",
    "        pdf[\"star\"].hist(bins=12)\n",
    "        plt.xlabel(\"Star\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Star Distribution\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../models/star_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # ----------------------------\n",
    "        # 2. Sentiment distribution\n",
    "        # ----------------------------\n",
    "        plt.figure(figsize=(6,4))\n",
    "        pdf[\"sentiment\"].value_counts().plot(kind=\"bar\")\n",
    "        plt.xlabel(\"Sentiment\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(\"Sentiment Distribution\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../models/sentiment_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # ----------------------------\n",
    "        # 3. Scatter Like – Dislike\n",
    "        # ----------------------------\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.scatter(pdf[\"like\"], pdf[\"dislike\"])\n",
    "        plt.xlabel(\"Like\")\n",
    "        plt.ylabel(\"Dislike\")\n",
    "        plt.title(\"Like vs Dislike\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../models/like_dislike_scatter.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # ----------------------------\n",
    "        # 4. Boxplot Likes theo sentiment\n",
    "        # ----------------------------\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.boxplot(x=\"sentiment\", y=\"like\", data=pdf)\n",
    "        plt.title(\"Like Distribution by Sentiment\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../models/like_by_sentiment.png\")\n",
    "        plt.close()\n",
    "\n",
    "        print(\"✔ Ảnh đã lưu vào: models\", )\n",
    "        # 5. Lấy toàn bộ comment worldcount\n",
    "        text_pdf = review_label.select(\"comment\").toPandas()\n",
    "        text = \" \".join(text_pdf[\"comment\"].fillna(\"\"))\n",
    "\n",
    "        wc = WordCloud(\n",
    "            width=1200,\n",
    "            height=800,\n",
    "            background_color=\"white\",\n",
    "            stopwords=STOPWORDS,\n",
    "            collocations=True\n",
    "        ).generate(text)\n",
    "\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.imshow(wc, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        path_wc = f\"../models/wordcloud.png\"\n",
    "        plt.savefig(path_wc)\n",
    "        plt.close()\n",
    "\n",
    "        print(\"✔ Saved WordCloud:\", path_wc)\n",
    "\n",
    "\n",
    "        # 6 .Heatmap\n",
    "        num_pdf = review_label.select(\"star\", \"like\", \"dislike\").toPandas()\n",
    "        corr = num_pdf.corr()\n",
    "\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        plt.tight_layout()\n",
    "        path_heat = f\"../models/correlation_heatmap.png\"\n",
    "        plt.savefig(path_heat)\n",
    "        plt.close()\n",
    "\n",
    "        print(\"✔ Saved Heatmap:\", path_heat)\n",
    "\n",
    "        # ============================\n",
    "        #  Chuẩn bị dữ liệu cho FP-Growth\n",
    "        # ============================\n",
    "        fp_df = review_label.select(\n",
    "            array(\n",
    "                \"sentiment\",\n",
    "                col(\"star\").cast(\"string\"),\n",
    "                when(col(\"like\") > 500, \"like_high\").otherwise(\"like_low\"),\n",
    "                when(col(\"dislike\") > 100, \"dislike_high\").otherwise(\"dislike_low\")\n",
    "            ).alias(\"items\")\n",
    "        )\n",
    "\n",
    "        # ============================\n",
    "        #  Train FP-Growth (Apriori)\n",
    "        # ============================\n",
    "        fp = FPGrowth(itemsCol=\"items\", minSupport=0.1, minConfidence=0.1)\n",
    "        model = fp.fit(fp_df)\n",
    "\n",
    "        rules = model.associationRules\n",
    "        rules_pdf = rules.toPandas()\n",
    "\n",
    "        # Chuyển luật thành dạng chuỗi dễ đọc\n",
    "        rules_pdf[\"rule\"] = rules_pdf[\"antecedent\"].apply(lambda x: \",\".join(x)) + \" → \" + \\\n",
    "                            rules_pdf[\"consequent\"].apply(lambda x: \",\".join(x))\n",
    "\n",
    "        # ============================\n",
    "        #  biểu đồ 7: Biểu đồ cột Confidence theo luật (đã chỉnh sửa)\n",
    "        # ============================\n",
    "\n",
    "        # Rút gọn chuỗi rule nếu quá dài (ví dụ > 40 ký tự)\n",
    "        def shorten(text, max_len=40):\n",
    "            return text if len(text) <= max_len else text[:max_len] + \"...\"\n",
    "\n",
    "        rules_pdf[\"rule_short\"] = rules_pdf[\"rule\"].apply(shorten)\n",
    "\n",
    "        # Lấy top 20 luật theo confidence (không bị rối chữ)\n",
    "        rules_top = rules_pdf.sort_values(\"confidence\", ascending=False).head(20)\n",
    "\n",
    "        plt.figure(figsize=(14, 10))   # ảnh lớn hơn cho dễ nhìn\n",
    "\n",
    "        sns.barplot(\n",
    "            y=\"rule_short\",\n",
    "            x=\"confidence\",\n",
    "            data=rules_top,\n",
    "            palette=\"Blues_r\"\n",
    "        )\n",
    "\n",
    "        plt.title(\"Association Rules – Confidence\", fontsize=16)\n",
    "        plt.xlabel(\"Confidence\", fontsize=13)\n",
    "        plt.ylabel(\"Rule\", fontsize=13)\n",
    "\n",
    "        # Tăng lề trái để nhãn không bị dính\n",
    "        plt.subplots_adjust(left=0.40)\n",
    "\n",
    "        # Giảm kích thước font nhãn\n",
    "        plt.yticks(fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path1 = f\"../models/association_rules_confidence.png\"\n",
    "        plt.savefig(save_path1, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(\"✔ Saved:\", save_path1)\n",
    "\n",
    "        # ============================\n",
    "        #  Vẽ biểu đồ 8: Scatter Support – Confidence\n",
    "        # ============================\n",
    "        plt.figure(figsize=(7,6))\n",
    "        plt.scatter(rules_pdf[\"support\"], rules_pdf[\"confidence\"])\n",
    "        plt.xlabel(\"Support\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        plt.title(\"Support vs Confidence\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path2 = \"../models/support_vs_confidence.png\"\n",
    "        plt.savefig(save_path2)\n",
    "        plt.close()\n",
    "\n",
    "        print(\"✔ Saved:\", save_path2)\n",
    "\n",
    "        # ============================\n",
    "        #  Vẽ biểu đồ 9: Scatter Lift – Confidence\n",
    "        # ============================\n",
    "        plt.figure(figsize=(7,6))\n",
    "        plt.scatter(rules_pdf[\"lift\"], rules_pdf[\"confidence\"])\n",
    "        plt.xlabel(\"Lift\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        plt.title(\"Lift vs Confidence\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path3 = \"../models/lift_vs_confidence.png\"\n",
    "        plt.savefig(save_path3)\n",
    "        plt.close()\n",
    "\n",
    "        print(\"✔ Saved:\", save_path3)\n",
    "\n",
    "    def predict_sentiment(review) :\n",
    "        review_label =  review.withColumn(\"label\" , when(col(\"star\") >= 8 , 1) \\\n",
    "                                                        .when(col(\"star\") >= 5 , 2) \\\n",
    "                                                        .otherwise(0)) \\\n",
    "                                                        .drop(\"sentiment\")\n",
    "        #  Tokenize comment\n",
    "        tokenizer = Tokenizer(inputCol=\"comment\", outputCol=\"words\")\n",
    "        remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "        # TF \n",
    "        vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"raw_features\")\n",
    "\n",
    "        #  IDF\n",
    "        idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "        # Classifier\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "        # Full pipeline\n",
    "        pipeline = Pipeline(stages=[tokenizer, remover, vectorizer, idf, lr])\n",
    "\n",
    "        train, test = review_label.randomSplit([0.8, 0.2], seed=42)\n",
    "        model = pipeline.fit(train)\n",
    "        predictions = model.transform(test)\n",
    "\n",
    "        predictions.select(\"comment\", \"label\", \"prediction\", \"probability\").show(truncate=False)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 6 : Tổng các đánh giá cảm xúc theo từng phim\n",
    "    # ===================================================================\n",
    "\n",
    "    def top_sentiment(review , movie) :\n",
    "        print(\"Analysis 5 : Total ratings sentiment for each movie\")\n",
    "\n",
    "        review_sentiment =  review.withColumn(\"Positive\" , when(col(\"star\") >= 8 , 1).otherwise(0)) \\\n",
    "                                    .withColumn(\"Neutral\" , when((col(\"star\") >= 5) & (col(\"star\") < 8) , 1).otherwise(0)) \\\n",
    "                                        .withColumn(\"Negative\" , when(col(\"star\") < 5 , 1).otherwise(0))\n",
    "\n",
    "        review_join = review_sentiment.join(broadcast(movie) , \"movie_id\" , \"inner\")\n",
    "\n",
    "        review_dt = review_join.dropDuplicates([\"review_id\"])\n",
    "\n",
    "        top_sentiment = review_join.groupBy(\"title\" , \"year\" , \"rating\" , \"review_ts\") \\\n",
    "                                    .agg(count(\"review_id\").alias(\"total_review\") ,\n",
    "                                        sum(\"Positive\").alias(\"Positive\") ,\n",
    "                                        sum(\"Negative\").alias(\"Negative\") ,\n",
    "                                        sum(\"Neutral\").alias(\"Neutral\"))\n",
    "        \n",
    "        return top_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad1a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbPipeline :\n",
    "    def __init__(self):\n",
    "        self.spark = SparkConfig.create_sparksession()\n",
    "        self.load = DataLoader()\n",
    "        self.clean = DataClean\n",
    "        self.analytics = AnalysisSentiment\n",
    "        self.result = {}\n",
    "\n",
    "    def load_data(self) :\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== DATA LOADING PHASE ===\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        self.movie = self.clean.movie_clean(self.load.movie_load())\n",
    "        self.actor = self.clean.actor_clean(self.load.actor_load())\n",
    "        self.review = self.clean.review_clean(self.load.review_load())\n",
    "\n",
    "        print(\"\\n All data loaded successfully\")\n",
    "\n",
    "    def run_analysis_1(self) :\n",
    "        try:\n",
    "            result = self.analytics.top_country(self.movie)\n",
    "            self.result[\"top_country\"] = result\n",
    "            return result\n",
    "        except Exception as e :\n",
    "            print(\"Error in Analysis 1 : \" , str(e))\n",
    "            raise\n",
    "\n",
    "    def run_analysis_2(self) :\n",
    "        try:\n",
    "            result = self.analytics.rating_per_year(self.review , self.movie)\n",
    "            self.result[\"rating_per_year\"] = result\n",
    "            return result\n",
    "        except Exception as e :\n",
    "            print(\"Error in Analysis 2 : \" , str(e))\n",
    "            raise\n",
    "\n",
    "    def run_analysis_3(self) :\n",
    "        try:\n",
    "            result = self.analytics.top_user_sentiment(self.review , self.movie)\n",
    "            self.result[\"top_user_sentiment\"] = result\n",
    "            return result\n",
    "        except Exception as e :\n",
    "            print(\"Error in Analysis 3 : \" , str(e))\n",
    "            raise\n",
    "\n",
    "    def run_analysis_4(self) :\n",
    "        try:\n",
    "            result = self.analytics.top_director_rate(self.actor , self.movie)\n",
    "            self.result[\"top_director_rate\"] = result\n",
    "            return result\n",
    "        except Exception as e :\n",
    "            print(\"Error in Analysis 4 : \" , str(e))\n",
    "            raise\n",
    "\n",
    "    def run_analysis_5(self) :\n",
    "        try:\n",
    "            result = self.analytics.top_sentiment(self.review , self.movie)\n",
    "            self.result[\"top_sentiment\"] = result\n",
    "            return result\n",
    "        except Exception as e :\n",
    "            print(\"Error in Analysis 5 : \" , str(e))\n",
    "            raise\n",
    "        \n",
    "    def run_all_analysis(self) :\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== ANALYSIS PHASE - RUNNING ALL ANALYSES ===\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        total_start = time.time()\n",
    "\n",
    "        self.run_analysis_1()\n",
    "        self.run_analysis_3()\n",
    "        self.run_analysis_4()\n",
    "        self.run_analysis_2()\n",
    "        self.run_analysis_5()\n",
    "\n",
    "        total_elapsed = time.time() - total_start\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"ALL ANALYSIS COMPLETED IN {total_elapsed:.2f}s\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def save_sql(self) :\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"=== SAVING TO POSTGRESQL ===\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        def save_psql(df , batch_id , name):\n",
    "            print(\"Batch id \" , str(batch_id) , \" :\")\n",
    "            print(f\"=== Save {name} into postgresql ===\")\n",
    "            print(\"Count in batch =\", df.count()) \n",
    "            df.show(5, truncate=False)\n",
    "            \n",
    "            try :\n",
    "                df.write.format(\"jdbc\").mode(\"append\") \\\n",
    "                            .option(\"driver\" ,\"org.postgresql.Driver\") \\\n",
    "                            .option(\"url\" , \"jdbc:postgresql://192.168.1.3:5432/imdb_sentiment\") \\\n",
    "                            .option(\"user\" , \"postgres\") \\\n",
    "                            .option(\"password\" ,\"minhhai123\") \\\n",
    "                            .option(\"dbtable\" , f\"public.{name}\") \\\n",
    "                            .save()\n",
    "            except Exception as e :\n",
    "                print(f\"Error to save {name} : \" , str(e))\n",
    "            \n",
    "\n",
    "        queries = []\n",
    "        for name , df in self.result.items() :\n",
    "            query =  df.writeStream.outputMode(\"append\") \\\n",
    "                            .foreachBatch(partial(save_psql , name = name)) \\\n",
    "                            .option(\"checkpointLocation\" , f\"/home/enovo/prj/test/check_points/{name}/\") \\\n",
    "                            .trigger(processingTime = \"5 seconds\") \\\n",
    "                            .start() \n",
    "            queries.append(query)\n",
    "            print(f\"Streming {name} started -> to postgreSQL\")\n",
    "        # self.spark.streams.awaitAnyTermination()\n",
    "        for q in queries :\n",
    "            q.awaitTermination()\n",
    "    def spark_stop(self) :\n",
    "        self.spark.stop()\n",
    "        print(\"=== Spark session stop ===\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d95ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"=== IMDB ANALYSIS SYSTEM ===\")\n",
    "    print(\"=\"*90)\n",
    "    try :\n",
    "        Pipeline = ImdbPipeline()\n",
    "\n",
    "\n",
    "        Pipeline.load_data()\n",
    "        Pipeline.run_all_analysis()\n",
    "        Pipeline.save_sql()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"=== ALL PIPELINE COMPLETED ===\")\n",
    "        print(\"=\"*90)\n",
    "    except Exception as e :\n",
    "        print(\"Pipeline failed : \" , str(e))\n",
    "        traceback.print_exc()\n",
    "# if __name__ == \"__main__\" :\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71debf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:37 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 6124 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "=== Starting load movie ===\n",
      "============================================================\n",
      "=== Loaded movie successfully ===\n",
      "\n",
      "============================================================\n",
      "=== Starting clean movie ===\n",
      "============================================================\n",
      "=== Cleaned movie successfully ===\n",
      "\n",
      "============================================================\n",
      "=== Starting load actor ===\n",
      "============================================================\n",
      "Batch id  22  :\n",
      "=== Save into postgresql ===\n",
      "=== Loaded actor successfully ===\n",
      "\n",
      "============================================================\n",
      "=== Starting clean actor ===\n",
      "============================================================\n",
      "=== Cleaned actor successfully ===\n",
      "\n",
      "============================================================\n",
      "=== Starting review actor ===\n",
      "============================================================\n",
      "=== Loaded review successfully ===\n",
      "\n",
      "============================================================\n",
      "=== Starting clean review ===\n",
      "============================================================\n",
      "=== Cleaned review successfully ===\n",
      "Analysis 2 : Analytics user Sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:43 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 6057 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  23  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 438:=================================>                     (12 + 8) / 20]\r"
     ]
    }
   ],
   "source": [
    "spark = SparkConfig.create_sparksession()\n",
    "movie = spark.read.json(\"../data/movies.json\")\n",
    "actor = spark.read.json(\"../data/actors.json\")\n",
    "review = spark.read.json(\"../data/reviews.json\")\n",
    "movie = DataClean.movie_clean(DataLoader().movie_load())\n",
    "actor = DataClean.actor_clean(DataLoader().actor_load())\n",
    "review = DataClean.review_clean(DataLoader().review_load())\n",
    "\n",
    "def save_psql(df , batch_id ):\n",
    "            print(\"Batch id \" , str(batch_id) , \" :\")\n",
    "            print(f\"=== Save into postgresql ===\")\n",
    "            print(\"Count in batch =\", df.count())  \n",
    "            df.show(5, truncate=False)   \n",
    "            try :\n",
    "                df.write.format(\"jdbc\").mode(\"append\") \\\n",
    "                            .option(\"driver\" ,\"org.postgresql.Driver\") \\\n",
    "                            .option(\"url\" , \"jdbc:postgresql://192.168.1.3:5432/imdb_sentiment\") \\\n",
    "                            .option(\"user\" , \"postgres\") \\\n",
    "                            .option(\"password\" ,\"minhhai123\") \\\n",
    "                            .option(\"dbtable\" , f\"public.top_user_sentiment\") \\\n",
    "                            .save()\n",
    "            except Exception as e :\n",
    "                print(f\"Error to save  : \" , str(e))\n",
    "df = AnalysisSentiment.top_user_sentiment(review , movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ffa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- review_ts: timestamp (nullable = true)\n",
      " |-- total_review: long (nullable = false)\n",
      " |-- total_like: long (nullable = true)\n",
      " |-- total_dislike: long (nullable = true)\n",
      " |-- like_ratio: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in batch = 0\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|title|rating|review_ts|total_review|total_like|total_dislike|CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END|\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "+-----+------+---------+------------+----------+-------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Error to save  :  [COLUMN_NOT_DEFINED_IN_TABLE] \"DOUBLE\" column `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END` is not defined in table `public`.`top_user_sentiment`, defined table columns are: `title`, `rating`, `review_ts`, `total_review`, `total_like`, `total_dislike`, `CASE WHEN ((sum(like) + sum(dislike)) > 0) THEN (sum(like) / (sum(like) + sum(dislike))) AS like_ratio ELSE 0 END`. SQLSTATE: 42703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:00:59 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000} milliseconds, but spent 6203 milliseconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  25  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 472:>                                                      (0 + 12) / 20]\r"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/23 20:01:24 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id  0  :\n",
      "=== Save into postgresql ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 522:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "df.writeStream.outputMode(\"append\") \\\n",
    "                            .foreachBatch(save_psql) \\\n",
    "                            .option(\"checkpointLocation\" , \"../check_points/\") \\\n",
    "                            .trigger(processingTime = \"5 seconds\") \\\n",
    "                            .start() \\\n",
    "                            .awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
